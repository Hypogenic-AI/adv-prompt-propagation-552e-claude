\section{Related Work}
\label{sec:related}

We organize related work into three themes: attack propagation models for multi-agent systems, vulnerability amplification through collaborative mechanisms, and defense frameworks.

\para{Attack propagation in multi-agent systems.}
\citet{lee2024prompt} introduced self-replicating prompt injection, demonstrating that infected agents can propagate malicious instructions to peers following a logistic growth pattern, with stronger models paradoxically being more dangerous when compromised. \citet{gu2024agentsmith} showed that a single adversarial image can trigger exponential infection across multimodal LLM agent populations, modeled with SIR-like epidemiological dynamics. More recently, ValueFlow~\citep{valueflow2026} formalized how value perturbations propagate through multi-agent DAGs using a $\beta$-susceptibility metric, confirming that perturbations amplify across hops. \citet{wolfwithin2024} demonstrated that a single covert adversarial agent can disproportionately affect system-level behavior. Unlike these works, which focus on infection rates or value drift, we measure the \emph{semantic mutation} of adversarial content as it propagates and systematically compare five distinct injection techniques.

\para{Vulnerability amplification through collaboration.}
Multi-agent debate systems are particularly vulnerable to adversarial exploitation. \citet{amplified2025} demonstrated a 185\% amplification of jailbreak success rates in debate settings compared to single-agent systems, driven by iterative refinement across rounds. MAD-Spear~\citep{madspear2025} showed that even one compromised agent out of six can influence debate outcomes through conformity pressure, exploiting LLMs' tendency toward herd behavior. \citet{resilience2024} studied how multi-agent systems respond to faulty agents, providing baseline resilience metrics. Our work differs in that we study collaborative task completion rather than debate, and we directly measure how the collaborative mechanism transforms adversarial content across agent roles.

\para{Topology-aware attacks and defenses.}
\toma~\citep{toma2025} introduced topology-aware multi-hop attacks with hierarchical payload encapsulation, achieving 40--78\% attack success rates across five topologies. Their \tguard defense achieves a 94.8\% blocking rate using topology-based trust scores. NetSafe~\citep{netsafe2024} analyzed how topological features like node centrality predict vulnerability, while G-Designer~\citep{gdesigner2024} used graph neural networks to architect robust communication topologies. These works suggest that topology is a critical factor in multi-agent security. Our results challenge this conclusion for \emph{generic} (topology-agnostic) injections, finding no significant topology effect, which implies that the topology dependence observed in prior work may stem from topology-\emph{aware} payload design rather than topology itself.

\para{Defense frameworks.}
AutoDefense~\citep{autodefense2024} uses multi-agent pipelines to filter and validate responses. BlindGuard~\citep{blindguard2025} addresses defense against unknown attacks using anomaly detection principles. On the detection side, \citet{liu2023prompt} provided taxonomies of prompt injection attacks and classifier-based detection approaches for LLM-integrated applications, and \citet{greshake2023indirect} established foundational concepts for indirect prompt injection through external data sources. Our findings on semantic mutation suggest that detection approaches must account for content transformation rather than relying on exact-match signatures.
