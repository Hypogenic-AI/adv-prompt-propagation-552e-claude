@article{lee2024prompt,
  title={Prompt Infection: {LLM}-to-{LLM} Prompt Injection within Multi-Agent Systems},
  author={Lee, Siyuan and Tiwari, Aarav},
  journal={arXiv preprint arXiv:2410.07283},
  year={2024}
}

@article{gu2024agentsmith,
  title={Agent Smith: A Single Image Can Jailbreak One Million Multimodal {LLM} Agents Exponentially Fast},
  author={Gu, Xiangming and Zheng, Xiaosen and Pang, Tianyu and Du, Chao and Liu, Qian and Wang, Ye and Jiang, Jing and Lin, Min},
  journal={arXiv preprint arXiv:2402.08567},
  year={2024}
}

@article{toma2025,
  title={Tipping the Dominos: Topology-Aware Multi-Hop Attacks on {LLM}-Based Multi-Agent Systems},
  author={Anonymous},
  journal={arXiv preprint arXiv:2512.04129},
  year={2025}
}

@article{valueflow2026,
  title={{ValueFlow}: Measuring the Propagation of Value Perturbations in Multi-Agent {LLM} Systems},
  author={Anonymous},
  journal={arXiv preprint arXiv:2602.08567},
  year={2026}
}

@article{amplified2025,
  title={Amplified Vulnerabilities: Structured Jailbreak Attacks on {LLM}-based Multi-Agent Debate},
  author={Anonymous},
  journal={arXiv preprint arXiv:2504.16489},
  year={2025}
}

@article{madspear2025,
  title={{MAD-Spear}: Conformity-Driven Prompt Injection on Multi-Agent Debate Systems},
  author={Anonymous},
  journal={arXiv preprint arXiv:2507.13038},
  year={2025}
}

@article{autodefense2024,
  title={{AutoDefense}: Multi-Agent {LLM} Defense against Jailbreak Attacks},
  author={Anonymous},
  journal={arXiv preprint arXiv:2403.04783},
  year={2024}
}

@article{netsafe2024,
  title={{NetSafe}: Exploring the Topological Safety of Multi-agent Networks},
  author={Anonymous},
  journal={arXiv preprint arXiv:2410.15686},
  year={2024}
}

@article{gdesigner2024,
  title={{G-Designer}: Architecting Multi-agent Communication Topologies via Graph Neural Networks},
  author={Anonymous},
  journal={arXiv preprint arXiv:2410.11782},
  year={2024}
}

@article{blindguard2025,
  title={{BlindGuard}: Safeguarding {LLM}-based Multi-Agent Systems under Unknown Attacks},
  author={Anonymous},
  journal={arXiv preprint arXiv:2508.08127},
  year={2025}
}

@article{greshake2023indirect,
  title={Not What You've Signed Up For: Compromising Real-World {LLM}-Integrated Applications with Indirect Prompt Injection},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  journal={arXiv preprint arXiv:2302.12173},
  year={2023}
}

@article{liu2023prompt,
  title={Prompt Injection Attacks and Defenses in {LLM}-Integrated Applications},
  author={Liu, Yupei and Jia, Yuqi and Geng, Runpeng and Jia, Jinyuan and Gong, Neil Zhenqiang},
  journal={arXiv preprint arXiv:2310.12815},
  year={2023}
}

@article{wolfwithin2024,
  title={The Wolf Within: Covert Injection of Malice into {MLLM} Societies via an {MLLM} Operative},
  author={Anonymous},
  journal={arXiv preprint arXiv:2402.14859},
  year={2024}
}

@article{resilience2024,
  title={On the Resilience of Multi-Agent {LLM} Collaboration with Faulty Agents},
  author={Anonymous},
  journal={arXiv preprint arXiv:2408.00989},
  year={2024}
}
